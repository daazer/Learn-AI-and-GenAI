# week-05-optimization - Day 03: Gradient Descent and LR Schedules

## Reading (5-15 minutes)
- [GD crash-course page](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent) - skim.
- [LR schedule concept](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) - concept only.

## How To Read (2-3 minutes)
- Write one signal that LR is too high from a loss curve.

## Build (Detailed Coding / Practice)
1. Create `week-05-optimization/code/day03_gd.py`.
2. Implement constant and decayed learning-rate schedules over convex toy objective.
3. Save loss curves to `artifacts/day-03-lr-curves.png`.

## Practice Drills
- Run one unstable high-LR case and keep screenshot/plot.

## Done When
- [ ] Schedule comparison plot exists.

