# week-08-transformers - Day 01: Attention Intuition

## Reading (5-15 minutes)
- [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) - intro+self-attention section.
- [Attention Is All You Need abstract](https://arxiv.org/abs/1706.03762) - abstract + figure 1.

## How To Read (2-3 minutes)
- Write one sentence each for query, key, and value.

## Build (Detailed Coding / Practice)
1. Create `week-08-transformers/code/day01_attention_intuition.py`.
2. Build 3-token toy attention example and verify row-wise softmax sums to 1.
3. Save attention table to `week-08-transformers/artifacts/day-01-attention.md`.

## Practice Drills
- Change one token embedding and inspect weight shift.

## Done When
- [ ] Toy attention math and artifact are complete.

