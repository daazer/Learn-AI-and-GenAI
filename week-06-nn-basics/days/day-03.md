# week-06-nn-basics - Day 03: Backpropagation

## Reading (5-15 minutes)
- [Backprop chain rule](https://cs231n.github.io/optimization-2/) - chain rule section.
- [Gradient check refresher](https://cs231n.github.io/neural-networks-3/) - skim.

## How To Read (2-3 minutes)
- Write chain rule for one weight path.

## Build (Detailed Coding / Practice)
1. Create `week-06-nn-basics/code/day03_backprop.py`.
2. Implement backward pass and compare selected gradients to numerical estimates.
3. Save max difference in `artifacts/day-03-backprop-check.txt`.

## Practice Drills
- Inject sign error once to ensure checker catches it.

## Done When
- [ ] Backprop gradients pass numeric sanity checks.

