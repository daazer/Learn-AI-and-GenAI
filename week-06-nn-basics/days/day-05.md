# week-06-nn-basics - Day 05: L2 and Dropout

## Reading (5-15 minutes)
- [Regularization intro](https://developers.google.com/machine-learning/crash-course/overfitting/regularization) - 8-10 min.
- [Dropout paper abstract](https://jmlr.org/papers/v15/srivastava14a.html) - read abstract.

## How To Read (2-3 minutes)
- Note when dropout must be disabled.

## Build (Detailed Coding / Practice)
1. Create `week-06-nn-basics/code/day05_regularization.py`.
2. Add L2 penalty and dropout to the two-layer training loop.
3. Compare no-reg vs L2 vs L2+dropout in `artifacts/day-05-regularization.csv`.

## Practice Drills
- Vary dropout rate 0.1 vs 0.5 and record effect.

## Done When
- [ ] Regularization comparison table exists.

